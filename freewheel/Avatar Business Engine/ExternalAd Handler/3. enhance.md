## Kafka Consumer的Offset Manual Commit实现

1. pc.Messages这个partitionConsumer的channel，是由brokerConsumer定期fetchMessage来填充的，每次都会填充一个batch的messages。
2. partitionConsumer是从pc.Messages这个channel里，一条条的消费消息，
3. 手动commit的目的，是为了保证在consumer重启的时候能够不丢失数据地进行消费
4. 方案：
   1. 关闭auto-commit
   2. 使用OffsetManager来管理offset
   3. 配置达到一定条数，手动commit一次
   4. 关闭consumer的时候，手动commit一次



## 处理ErrOffsetOutOfRange



1. 如何关闭和重启一个partition的PartitionConsumer
2. 



## 根据不同的process error来决定failed case的处理



golang标准库中只有Error接口这一种error类型，如果是没有做封装的话，一般只能通过类似于strings.Contains(err.Error(), "Access denied")这种语句来判断error类型

与业务处理的error不同，mysqlError、osError、netError等等这种技术上的error在特定的业务场景下，是需要特殊处理的，比如设置retry或者block等等

在本service中，message process过程中主要涉及到的是mysqlError和netError，可以使用"github.com/go-sql-driver/mysql"这个lib封装的*mysql.MySQLError，以及\*net.OpError来断言判断mysql db的一些error和tcp conn的一些error

【golang的error处理非常不优雅】

相关参考：

https://meilihao.github.io/go-database-sql-tutorial_zh-CN/errors.html

https://liudanking.com/network/go-%E4%B8%AD%E5%A6%82%E4%BD%95%E5%87%86%E7%A1%AE%E5%9C%B0%E5%88%A4%E6%96%AD%E5%92%8C%E8%AF%86%E5%88%AB%E5%90%84%E7%A7%8D%E7%BD%91%E7%BB%9C%E9%94%99%E8%AF%AF/

https://docs.hacknode.org/gopl-zh/ch7/ch7-11.html

【处理方式】

1. 若err为属\*net.OpError，判定为技术型错误，重试几次无果后，阻塞consumer goroutine（这时goroutine只能被强制关闭，后续重启不会有影响，且一旦技术错误恢复，goroutine会马上正常消费处理message）（*mysql.MySQLError目前没有判定在此类中）
2. 若为其他err，判定为业务型错误，重试几次无果后放弃处理，继续消费message进行处理，不影响offset的commit
3. 重试次数可以通过进行config配置
4. 





## Kafka ERROR的捕获以及处理

思考点：

（1） 怎么能捕获到Kafka的PartitionConsumer运行时的Error？

（2）怎么处理各种Kafka的PartitionConsumer运行时的Error？

（3）Kafka的PartitionConsumer线程终止时，会丢失数据吗？

（4）怎么manual重启某一个PartitionConsumer的线程？

解决过程：

根据PartitionConsumer的文档，PartitionConsumer这个线程只会在一种error case情况下停止，其他的error case下只会不断的重试。

![image-20210105103035695](/Users/lugao/Library/Application Support/typora-user-images/image-20210105103035695.png)

因此，我们可以开启KafkaConfig.Consumer.Return.Errors = true，从Errors的channel中获取error信息，当发现有导致partitionConsumer shutdown的error（ErrOffsetOutOfRange）出现时，重启这个partitionConsumer，并且让它从该partition的oldestOffset开始消费，简单粗暴的避免message丢失

![image-20210105171719608](/Users/lugao/Library/Application Support/typora-user-images/image-20210105171719608.png)





## Kafka Send ERROR：dial tcp 172.20.0.4:9092: i/o timeout 

这是一种kafka和主机程序处于不同网络环境下会发生的问题！（比如，docker内的kafka容器 & localhost的client程序）

说明：

首先，我们需要在producer/consumer这些client中为kafka配置**代理ip**，以便client能找到相应的kafka服务。可是这里的代理ip只是让client与kafka建立**initial connection**，之后kafka会在这次connection中返回关于partition的leader broker的metadata（包括broker的**实际ip**）。而后client在实际produce或者consume时，才会再尝试去连接相应topic的metadata中的broker实际ip。所以，当实际broker ip与client ip在同一局域网下能直连的时候，不会出现任何问题，以上细节对用户是透明的；但是两者若不在同一局域网下，就无法ping通，生产或者消费就会失败。

解决：

思路是“把metadate返回的实际ip经过一层转义，暴露给client可以直连的局域网ip”，更改kafka的listener相关配置。其中，listener定义的是kafka服务监听的ip和port，advertised_listener定义的则是对应listener分别对外监听和对外返回的ip和port，kafka_inter_broker_listener_name定义的是kafka服务内部的监听配置名。

举例：

当kafka:9092收到连接请求，将会映射到kafka:9092上进行服务，且返回的broker metadata为kafka:9092；当localhost:9094收到连接请求，将会映射到kafka:9094上进行服务，且返回的broker metadata为localhost:9094。

而kafka_inter_broker_listener_name为INTERNAL，表示的是：INTERNAL定义的这一组互为映射的listener是kafka在局域网内部使用的配置（比如在启动Kafka服务，创建partition配置lead的时候）。

![image-20201127111807026](file:///Users/lugao/Library/Application Support/typora-user-images/image-20201127111807026.png?lastModify=1616125200?lastModify=1628058915)

参考：https://www.confluent.io/blog/kafka-listeners-explained/