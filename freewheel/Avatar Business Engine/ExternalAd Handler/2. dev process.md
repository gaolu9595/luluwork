# DEV PROCESS



[TOC]



## CLI Start

使用命令行启动，采用cli.NewApp()创建一个golang的cli程序



## protobuf

1. brew install protobuf

2. go get -u github.com/golang/protobuf/protoc-gen-go

3. de_request.proto 定义

4. de_request.proto 编译: **protoc --go_out=[objective path] [source path]**

   1. “protoc --go_out=...”，找不到protoreflect的google.golang.org/protobuf的包
   2. `github.com/golang/protobuf`文档，里边提到`v1.4.0`版本后, 后边代码将交由`google.golang.org/protobuf` Repo维护，**在序列化的时候会新加三个字段：state/cacheSize/unknownFields**
   3. 需要启用vendor管理自己service的依赖包，加入`google.golang.org/protobuf`

5. service内部的vendor依赖包管理：

   1. gopath下，go get -u github.com/kardianos/govendor
   2. service目录下，govendor init，govendor list， govendor fetch +out

6. de_request.pb.go 理解

7. 练习序列化和反序列化protobuf数据，解析出相应格式的message

   1. marshal是序列化
   2. unmarshal是反序列化

   <img src="/Users/lugao/Library/Application Support/typora-user-images/image-20201028151324162.png" alt="image-20201028151324162" style="zoom:33%;" />

8. 在我们定义的protobuf中，agency_id的类型是int32，而external_ad表中的agency_id类型为string，中间的类型转换需要注意一下：agencyId := strconv.Itoa(int(request.GetExternalAd().GetAgencyId()))

9. 

## Mysql Connection & Operation

1. 解决Mysql连接的困惑
   1. 连接池是一种节省频繁创建销毁数据库连接的好方法，同时适用于单线程和多线程的场景
   2. 一个事务需要一个connection，事务中所有的sql语句都在这个connection中执行
   3. 事务的隔离级别很重要，用于应付并发
   4. 一条单独的sql语句其实就相当于一个事务，因此一条单独的sql语句的执行需要一个connection
   5. golang中的线程池init：sql.Open，db.SetMaxIdleConns，db.SetMaxOpenConns
   6. golang中创建事务：db.BeginTx
2. config文件的加载
   1. 使用urfave/cli库，编写命令行程序	
   2. 因为我们的数据来源是kafka，所以不会用到http和grpc的东西，所以不复用freewheel的servicekit.Server中的Initializable接口，自己重新仿写一套cli的处理逻辑
   3. config解析：复用freewheel的servicekit.Server中的Config
3. initDB：
   1. 创建连接池，设置各种参数
   2. 测试连接：local的mysql / docker部署的mysql

## Docker部署mysql环境，k8s管理Docker容器

1. docker-compose的方式，对参数的表示更加直观
2. docker-compose中的build指定Dockerfile的路径，在docker-compose up时会自动去找到这个Dockerfile加载
3. docker部署的mysql，iTerm输入“docker exec -it 43c777fc3ad08fd827dfadb451f5b3e7c59e4c9af8af9cb49f2816f3f1414dce /bin/sh; exit”进入mysql容器中测试
4. 

## GORM框架

1. **gormt工具**，将mysql表转换成golang的struct

   1. 下载的时候，直接下载其bin，更改system preference之后再运行

   2. 需要配置好sigularTable（true表示不使用复数表名）等各种转换设置

   3. 在转换成struct时需不需要外键的完整对象，需要视业务需求而定，配置项为**is_foreign_key : false/true** (我在项目中没有导出含外键对象的struct，因为感觉复杂度会增高且没必要）

   4. sql中关于字段类型的定义，转换成golang中的类型时，可能有一点点形式上的差异（如tinyint(1)类型在golang中会使用bool类型代替）

   5. sql中关于default值的定义，转换成golang中的struct时，不会直接表现在gorm tag中，**需要手动加上**，这样在向mysql写数据的时候即使not fill all fields也不会出错

      1. seat表：![image-20201112134305483](/Users/lugao/Library/Application Support/typora-user-images/image-20201112134305483.png)

      2. external_ad表：![image-20201112151539272](/Users/lugao/Library/Application Support/typora-user-images/image-20201112151539272.png)

      3. campaign表：

         ![image-20201117114434985](/Users/lugao/Library/Application Support/typora-user-images/image-20201117114434985.png)

         ![image-20201117114455173](/Users/lugao/Library/Application Support/typora-user-images/image-20201117114455173.png)

      4. banner表：

         ![image-20201117165542267](/Users/lugao/Library/Application Support/typora-user-images/image-20201117165542267.png)

         ![image-20201117165609673](/Users/lugao/Library/Application Support/typora-user-images/image-20201117165609673.png)

      5. External_ad_mapping表

         ![image-20201117171858021](/Users/lugao/Library/Application Support/typora-user-images/image-20201117171858021.png)
         
      6. Bidder表
      
         ![image-20201204135557078](/Users/lugao/Library/Application Support/typora-user-images/image-20201204135557078.png)
      
         ![image-20201204135625273](/Users/lugao/Library/Application Support/typora-user-images/image-20201204135625273.png)
      
         

2. gorm的**autoMigrate**，将golang的struct直接转换成mysql表(比较适合表少的情况)

3. 需要使用**gorm.Open()**来创建MySQL连接，**db.LogDebug()**展示gorm使用中的sql语句及代码运行信息

4. gorm***将没找到数据也定义为Error返回***（但这其实并不是程序运行上的错误），这是一个坑点，我们需要从业务层面再来进一步区分是业务error还是程序error

5. db.First()根据主键来查询记录时，只支持***主键类型为整型***

   ```go
   // 使用主键获取记录
   db.First(&user, 10)
   //// SELECT * FROM users WHERE id = 10;
   ```

6. **插入含有外键约束的记录**时，不需要先创建外键对象

7. 通过struct来查询时，***无法查询到非零字段***

   <img src="/Users/lugao/Library/Application Support/typora-user-images/image-20201112140317569.png" alt="image-20201112140317569" style="zoom:33%;" />

8. **db.RowsAffected**字段，代表着被update/insert/delete所影响的行数，理论上来说1是正常的（大于1说明操作会影响到其他行，等于0说明操作失败）

9. 

## Golang接口/指针等语法

1. 接口：只要某个struct实现了一个interface的所有方法，那么这个stuct就implement了这个interface

2. golang中的调用是通过package来找的，一个package下不能有同名的同类型声明

3. golang中的循环调用error，可以通过interface的方式来避免（如我们项目中的InitializerInterface这个interface就是为了解决这个问题）

4. 以json格式来打印结构体

   ```go
   bytes, _ := json.Marshal(bidder)
   fmt.Println(string(bytes))
   ```

5. golang中的错误和异常处理：https://www.jianshu.com/p/f30da01eea97

6. golang中的**int 是**带符号整数**类型**，其大小至少为32**位**。 它**是**一种确切的**类型**，而不是int32 的别名。

7. golang的公有interface和私有struct可以一起实现多态（如我们项目中的handler和dao层的设置）

8. golang的struct中嵌套struct可以实现继承（但是一般来说，推荐使用composition而不是inheritance）

9. golang不支持同名方法的重载

10. defer关键字，可以用于在函数return之前执行一些固定的收尾工作（注意⚠️：return语句不是一个原子语句，defer内容会在return语句赋值之后返回之前执行，要特别注意不要弄错咯）

11. slice和array的定义要注意区别

12. map的遍历，使用map[e]的方式(return e.val, existence)。即使e不存在，也不会报错，会返回该类型的初始值以及false



## 代码结构设计

1. gorm.DB这个对象是全局的，因此用到它的seatDao和externalAdDao最好也设置为每个线程中唯一拥有，采用单例模式（通过interface、私有struct和公有Get方法实现）
2. 需要被多个package使用到的对象，是通过面向对象的方式传递，还是通过函数调用来进行参数传递呢？（使用面向对象的方式吧）
3. error要逐层地来包装和捕获，不必要返回error的地方就不要返回
4. 

## 使用Makefile脚本工具



## Deduplicate设计与实现

1. 使用global带time window的一个缓存结构(如LRU Cache)，存储10min（DE load mysql的时间间隔）内所有线程的processor处理过的seat和external_ad
2. LRU Cache（**Least Recently Used**）的实现
   1. 事务隔离级别：gorm默认是使用数据库的，如mysql为“可重复读”（gorm创建事务时不能手动设置隔离级别）
   2. golang的sync包，提供lock（互斥锁、读写锁）、pool和waitGroup等
   3. 缓存结构：拟采用map（key为seatId或者externalAdId，value为expiredTime）
   4. 超时删除：主要有主动删除/被动删除两种方式（主动删除需要一个守护进程，耗CPU；被动删除不能及时删除过期key，耗内存），拟采用主动删除
   5. 锁：拟采用sync.RWMutex
   6. 将ttl加到config配置中
   7. 创建一个daemon goroutine，自动检查过期的元素并删除（使用time.Ticker间隔定时器，内部包含一个C通道来定期传输时间，搭配select case使用）
   8. **启发**：使用组合的方式创建一个新的struct来完成一些存储和操作，对于一些守护后台进程可以用runtime.SetFinalizer来优雅的执行关闭
3. 对seat和external_ad分别设置一个flag，检查seat和external_ad是否已被处理过，按照flag来走后面的处理流程
4. 在进行sql操作时，也会先判断一下seat和external_ad是否已经存在，存在的话就不处理了

## Kafka 生产&消费

1. kafka生产者，按照什么key来分发message到partition （对后续dedup目前没影响，目前采用externalAdId和seatId的哈希）

2. 根据估计，external_ad表每小时插入2000-7000行记录不等，平均每行记录大小为2kb，每小时kafka的负载仅为MB级别；campaigns、banners等表数据量更小，无压力，可忽略

3. 使用sarama和sarama-client框架，需要在go/src目录下执行govendor fetch github.com/Shopify/sarama来更新这个包，原来的包不支持consumer-group（有一些依赖如gokrb5等的下载遇到了很多繁琐的问题，需要一个个手动来下载，贼麻烦……不过挺住吧）

4. **sarama中的consumer模式：**

   整理一下 partitionConsumer 与 brokerConsumer 之间的交互还是有点复杂的，大概是：

   1. partitionConsumer 通过 broker.input 这个 chan 加入 brokerConsumer 的订阅；
   2. 加入订阅后，brokerConsumer 每次 fetchNewMessages 得到一批消息，会发给每个 partitionConsumer 的 feeder chan；
   3. 每个 partitionConsumer 解析 feeder chan 的数据得到 对应的消息列表，同时设置自身的 responseResult，设置 brokers.acks 这个 WaitGoup 执行 Done()，表示处理完毕该批次；
   4. brokerConsumer 等待每个 partitonConsumer 处理完毕该批次，处理所有 partitionConsumer 的 responseResult 后循环 fetchNewMessages；

5. consumer的终止：

   1. 使用waitgroup来控制多个partitionConsumer都消费完消息
   2. 使用os.Signal的channel来控制consumer的终止（注意⚠️：每个goroutime内部都需要注册一个signal的Notifier，才能保证这些goroutine都能被终止。如果共享signal监听的话，有多少个goroutine就需要多少个signal来进行一一终止）
   3. 

6. consumer的offset手动提交:

   1. brokerConsumer 会负责发起 FetchRequest 的主循环，每轮迭代拉取一批消息，发送给每个 partitionConsumer 再转给用户的 messages chan。通过 acks 这个 WaitGroup 来协调每个 partitionConsumer 对这一批次的消息的处理节奏。
   2. 非阻塞channel：使用goroutine，让channel读和写不在一个线程内就ok
   3. 使用offset manager来实现手动offset的提交

## 定时处理新的to-complete为0的seat，为其创建相应的records

1. https://cloud.tencent.com/developer/article/1422445 golang中cron定时任务的使用教程
2. 在为新complete的seat创建对应的bidder时，需要ghost bidder的信息，这里怎么解决？（使用磁盘存储的方式来存下我们此前处理过的unknown seat和对应generic bidder；定时查该磁盘文件，对新complete的seat创建bidder/campaign/banner这些信息，创建完成后删除这条记录）
3. golang持久化技术，追加存储（csv文件）
4. 业务知识：**seat表中的seatId和buyer_platform_id一起唯一表示一个seat，而bidder表中的agency_id与external_id（即对应seat_id）和buyer_platform_id一起唯一表示一个bidder**
5. 

## Kafka Send ERROR：dial tcp 172.20.0.4:9092: i/o timeout 

这是一种kafka和主机程序处于不同网络环境下会发生的问题！（比如，docker内的kafka容器 & localhost的client程序）

说明：

首先，我们需要在producer/consumer这些client中为kafka配置**代理ip**，以便client能找到相应的kafka服务。可是这里的代理ip只是让client与kafka建立**initial connection**，之后kafka会在这次connection中返回关于partition的leader broker的metadata（包括broker的**实际ip**）。而后client在实际produce或者consume时，才会再尝试去连接相应topic的metadata中的broker实际ip。所以，当实际broker ip与client ip在同一局域网下能直连的时候，不会出现任何问题，以上细节对用户是透明的；但是两者若不在同一局域网下，就无法ping通，生产或者消费就会失败。

解决：

思路是“把metadate返回的实际ip经过一层转义，暴露给client可以直连的局域网ip”，更改kafka的listener相关配置。其中，listener定义的是kafka服务监听的ip和port，advertised_listener定义的则是对应listener分别对外监听和对外返回的ip和port，kafka_inter_broker_listener_name定义的是kafka服务内部的监听配置名。

举例：

当kafka:9092收到连接请求，将会映射到kafka:9092上进行服务，且返回的broker metadata为kafka:9092；当localhost:9094收到连接请求，将会映射到kafka:9094上进行服务，且返回的broker metadata为localhost:9094。

而kafka_inter_broker_listener_name为INTERNAL，表示的是：INTERNAL定义的这一组互为映射的listener是kafka在局域网内部使用的配置（比如在启动Kafka服务，创建partition配置lead的时候）。

<img src="/Users/lugao/Library/Application Support/typora-user-images/image-20201127111807026.png" alt="image-20201127111807026" style="zoom:50%;" />

参考：https://www.confluent.io/blog/kafka-listeners-explained/



## Unit Test

1. handler、cache、processor：测试流程逻辑正确性，需要用到mock和assert（事务单测时还需要用到sqlmock，模拟一个db事务的begin、commit和rollback）【这儿有个nil的坑，没有正面解决，使用创建单测专用变量的方式规避了】

2. dao：测试数据库操作正确性，需要启动一个temporary mysql来assert验证（sqlmock）

3. 一个shadowed err return的问题：在事务操作时，经常会用到defer，但是defer的err有时候会是shadowed error，很容易出现混乱（shadowed error：上层的同名error。）

   **where？**

   　　Go程序函数中在通过 return关键字返回的时候，报错

   **why?**

   　　变量作用域的问题，在子作用域定义一个上层作用域的同名的变量

   ![image-20201225163230034](/Users/lugao/Library/Application Support/typora-user-images/image-20201225163230034.png)

## import cycle bug

原因：A依赖B，B依赖A，造成循环依赖

解决：可以用interface来解决

## no vendored package was allowed

原因：有多个vendor下都有相同的包，编译时不知道该使用哪个依赖包

解决：解决包冲突，查看go版本的SDK中的依赖

## sql: unknown driver "mysql" (forgotten import?)

原因：未导入mysql驱动的依赖包

解决：import _ "github.com/go-sql-driver/mysql"（ “_”下划线表示这个包在代码中不会显式地被调用，将作为副作用使用）

## mysql端口冲突问题

docker-compose中的port环境变量：“现port：默认port”

原因：本地的mysql和docker启动的mysql，都使用3306端口，造成golang project连接127.0.0.1:3306时选择mysql出问题

解决：停掉或更改本地mysql的端口号 / 更改docker中mysql的端口号

## mysql datetime与golang time.Time形式不一致的问题（使用gorm）

问题：

mysql中的datetime和date类型，marshal后展示格式为“2020-11-16 10:10:10”；

而golang中的time.Time类型，marshal后的展示格式为“2020-11-16 10:10:10 +0000 UTC ”；

两者格式的不一样，使得用golang读写mysql时涉及到许多格式上的问题

参考：https://l1905.github.io/golang/mysql/2020/07/14/golang-user-mysql-datetime/

解决方案：

方案1: 在连接mysql时，将参数parseTime设为false，表示“读写mysql时不会将mysql的datetime/date类型自动转换成golang的time.Time类型，而将直接转换成文本字符串string类型”，这样的话两者在展示格式上将保持一致了。（缺陷：在大部分程序中， 我们还是需要将时间类型设置为time.Time，方便我们进行时间到字符串，时间比较等一些操作。所以这种方式过于死板，不够灵活）

方案2: parseTime依旧设为true，读写mysql时golang的time.Time类型能与mysql的datetime/date类型自动转换。但是我们需要自定义一个time.Time的别名（如MyTime类型）来执行独特的marshal函数，使得在展示MyTime类型的时候能得到和mysql中的datetime/date一样的格式。

## mysql错误“Incorrect datetime value: '0000-00-00 00:00:00'”

原因：MySQL5.7以后，默认使用NO_ZERO_DATE模式，所以'0000-00-00 00:00:00'这种datetime被认为是无效的

解决：

方案1: 改自己的业务逻辑，避免出现'0000-00-00 00:00:00'值

方案2: 改MySQL配置

## Mid-term Discussion

目录结构「main.go、vendor、proto、config、app」

业务流程「命令行启动，初始化，模拟从Kafka取数据处理和commit，反序列化protobuf，创建handler和dao，业务逻辑梳理，processor/handler/dao层分工，gorm框架读写mysql，error捕获是逐层的」

后续安排「流量估计，看kafka相关的东西，UT」



## GOMOCK

lugao@lugao-mac:~/work/go/src/se_external_ad_service$     mockgen -source=app/dao/external_ad_dao.go -destination=mock.go【报错：command not found】

lugao@lugao-mac:~/work/go/src/se_external_ad_service$     /Users/lugao/test/go-lib/bin/mockgen  -source=app/dao/external_ad_dao.go -destination=mock.go 【成功】



