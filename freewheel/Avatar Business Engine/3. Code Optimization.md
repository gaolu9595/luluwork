# Optimization

[TOC]

## Use Consumer Group instead of Consumer

### 原有的assign consumer模式 (Kafka_consumer.go)

1. 使用一个BrokerConsumer来消费所有配置的topic：

   ```go
   consumer, err := sarama.NewConsumer(BrokerList, KafkaConfig)
   ```

2. 用一个broker来新建一个client，为其创建offsetManager来管理offset

   ```go
   client, err := sarama.NewClient(BrokerList, KafkaConfig)
   offsetManager, err := sarama.NewOffsetManagerFromClient("AvatarEngine_group", client)
   ```

3. 为每个topic的每个partition手动创建一个对应的PartitionConsumer，指定其从上次commit成功的offset开始消费

   ```go
   pc, err = consumer.ConsumePartition(topic, p, nextOffset+1)
   ```

4. 监听PartitionConsumer的Messages chan，进行消息处理，并手动或自动实现offset commit

   ```go
   for {
      select {
      // handle the error which will shut down the partition consumer
      case err := <-pc.Errors():
         XXXXXXXX
      // process consumed messages (a batch of messages fetched and dispatched by brokerConsumer)
      case message := <-pc.Messages():
         XXXXXXXX
      // if signal happens, terminate the consumer goroutine
      case <-signals:
         XXXXXXXX
      default:
         continue
      }
   }
   ```

5. 整理一下 sarama库中partitionConsumer 与 brokerConsumer 之间的交互，大概是：

   1. partitionConsumer 通过 broker.input 这个 chan 加入 brokerConsumer 的订阅；
   2. 加入订阅后，brokerConsumer 每次 fetchNewMessages 得到一批消息，会发给每个 partitionConsumer 的 feeder chan；
   3. 每个 partitionConsumer 解析 feeder chan 的数据得到 对应的消息列表，同时设置自身的 responseResult，设置 brokers.acks 这个 WaitGoup 执行 Done()，表示处理完毕该批次；
   4. brokerConsumer 等待每个 partitonConsumer 处理完毕该批次，处理所有 partitionConsumer 的 responseResult 后循环 fetchNewMessages；

### 新的consumer group模式

思路：

1. 对每个topic都指定一个consumer group，不同于原来的一对多消费（方便ops部署扩展监控）
2. 将consume和process分离开来，中间引入一个chan进行解耦合，使得processor的线程数不再依赖于topic*partition的数量，可以灵活地根据CPU的计算能力来配置processor的线程数（processor线程的处理速度是不可预知的，因此无法保证同一partition的message处理是顺序的，实现manual commit会有一些问题，kafka官方不推荐这种方式）**【kafka的partition设计之初就是为了迎合大数据和多线程的，所以通过指定partition数目来约定后端processor数目也是合理的，是比较合理的捆绑】**

consumer group及sarama探索：

1. **Consumer Group中的Consumer个数**一般来说并不是代码里强行写死的，它可以随着程序的部署扩展紧缩而增加减少，其能自动管理其Rebalance行为。如果要在一套代码里为某一个consumer group创建多个consumer，需要指定这多个consumer从同名的ConsumerGroup而来
2. sarama中，不论是自行实现partition consumer还是使用consumer group，实质都是通过**offset_manager的Commit()**来实现**AutoCommit.Enable=false**时的手动commit的，且该操作为**同步阻塞**操作（Note: calling Commit performs a blocking synchronous operation.）
3. sarama中，创建consumerGroup时提交的consumerGroupHandler实例实质会为每个topic+partition的组合创建一个自己的ConsumerClaim()，方便管理每个topic+partition的消费情况
4. Consumer Group中Consumers的消费有auto assign和custom assign两种方式，不论是哪种方式**consumers数目是必须小于等于partition数目**的。auto assign模式下，consumer的加减会自动调用group的reblance实现partition的分配；custom assign模式下，consumer在加进来的时候就已经指定好了去消费哪些partition。

实现：





## Golang的多线程

### channel支持线程间通信

channel本质是数据流动，分为阻塞和非阻塞channel两种

阻塞channel的读写不能在同一个线程中，否则会死锁

非阻塞channel的读写可以在同一个线程中，但是如果没有数据pull的话也会阻塞

### channel是线程安全的，并发首选

使用通信来共享内存，而不是使用共享内存来通信

在channel和mutex之间，golang推荐首选channel

channel是线程安全的，可以被多个goroutine同时读写，我们不需要考虑其数据冲突

### 优雅的检查channel的关闭

https://www.cnblogs.com/-wenli/p/12350181.html

使用ok检查channel是否关闭且是否清空了所有数据，然后break或者将channel置为nil（select不会在nil的channel上等待）

### select-case的随机监听以及优先级监听

```go
func worker2(ch1, ch2 <-chan int, stopCh chan struct{}) {
	for {
		select {
		case <-stopCh:
			return
		case job1 := <-ch1:
			fmt.Println(job1)
		case job2 := <-ch2:
		priority:
			for {
				select {
				case job1 := <-ch1:
					fmt.Println(job1)
				default:
					break priority
				}
			}
			fmt.Println(job2)
		}
	}
}
```

### 优雅的执行和检查goroutine的关闭

1. signals
2. sync.WaitGroup
3. context.Cancel